{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft GraphRAG: Enhancing Retrieval-Augmented Generation with Knowledge Graphs\n",
    "\n",
    " \n",
    "## Overview\n",
    "\n",
    " \n",
    "Microsoft GraphRAG is an advanced Retrieval-Augmented Generation (RAG) system that integrates knowledge graphs to improve the performance of large language models (LLMs). Developed by Microsoft Research, GraphRAG addresses limitations in traditional RAG approaches by using LLM-generated knowledge graphs to enhance document analysis and improve response quality.\n",
    "\n",
    "## Motivation\n",
    "\n",
    " \n",
    "Traditional RAG systems often struggle with complex queries that require synthesizing information from disparate sources. GraphRAG aims to:\n",
    "Connect related information across datasets.\n",
    "Enhance understanding of semantic concepts.\n",
    "Improve performance on global sensemaking tasks.\n",
    "\n",
    "## Key Components\n",
    "\n",
    "Knowledge Graph Generation: Constructs graphs with entities as nodes and relationships as edges.\n",
    "Community Detection: Identifies clusters of related entities within the graph.\n",
    "Summarization: Generates summaries for each community to provide context for LLMs.\n",
    "Query Processing: Uses these summaries to enhance the LLM's ability to answer complex questions.\n",
    "## Method Details\n",
    "\n",
    "Indexing Stage\n",
    "\n",
    " \n",
    "Text Chunking: Splits source texts into manageable chunks.\n",
    "Element Extraction: Uses LLMs to identify entities and relationships.\n",
    "Graph Construction: Builds a graph from the extracted elements.\n",
    "Community Detection: Applies algorithms like Leiden to find communities.\n",
    "Community Summarization: Creates summaries for each community.\n",
    "\n",
    "Query Stage\n",
    "\n",
    " \n",
    "Local Answer Generation: Uses community summaries to generate preliminary answers.\n",
    "Global Answer Synthesis: Combines local answers to form a comprehensive response.\n",
    "\n",
    "\n",
    "## Benefits of GraphRAG\n",
    "GraphRAG is a powerful tool that addresses some of the key limitations of the baseline RAG model. Unlike the standard RAG model, GraphRAG excels at identifying connections between disparate pieces of information and drawing insights from them. This makes it an ideal choice for users who need to extract insights from large data collections or documents that are difficult to summarize. By leveraging its advanced graph-based architecture, GraphRAG is able to provide a holistic understanding of complex semantic concepts, making it an invaluable tool for anyone who needs to find information quickly and accurately. Whether you're a researcher, analyst, or just someone who needs to stay informed, GraphRAG can help you connect the dots and uncover new insights.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Microsoft GraphRAG represents a significant step forward in retrieval-augmented generation, particularly for tasks requiring a global understanding of datasets. By incorporating knowledge graphs, it offers improved performance, making it ideal for complex information retrieval and analysis.\n",
    "\n",
    "For those experienced with basic RAG systems, GraphRAG offers an opportunity to explore more sophisticated solutions, although it may not be necessary for all use cases.\n",
    "Retrieval Augmented Generation (RAG) is often performed by chunking long texts, creating a text embedding for each chunk, and retrieving chunks for including in the LLM generation context based on a similarity search against the query. This approach works well in many scenarios, and at compelling speed and cost trade-offs, but doesn't always cope well in scenarios where a detailed understanding of the text is required.\n",
    "\n",
    "GraphRag ( [microsoft.github.io/graphrag](https://microsoft.github.io/graphrag/) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/Microsoft_GraphRag.svg\" alt=\"adaptive retrieval\" style=\"width:100%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this notebook you can use either OpenAI API key or Azure OpenAI key. \n",
    "Create a `.env` file and fill in the credentials for your OpenAI or Azure Open AI deployment. The following code loads these environment variables and sets up our AI client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_API_KEY=\"\"\n",
    "AZURE_OPENAI_ENDPOINT=\"\"\n",
    "GPT4O_MODEL_NAME=\"gpt-4o\"\n",
    "TEXT_EMBEDDING_3_LARGE_DEPLOYMENT_NAME=\"\"\n",
    "AZURE_OPENAI_API_VERSION=\"2024-06-01\"\n",
    "\n",
    "OPENAI_API_KEY=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "from openai import AzureOpenAI, OpenAI\n",
    "\n",
    "AZURE=True #Change to False to use OpenAI\n",
    "if AZURE:\n",
    "    AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    GPT4O_DEPLOYMENT_NAME = os.getenv(\"GPT4O_MODEL_NAME\")\n",
    "    TEXT_EMBEDDING_3_LARGE_NAME = os.getenv(\"TEXT_EMBEDDING_3_LARGE_DEPLOYMENT_NAME\")\n",
    "    AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "    oai = AzureOpenAI(azure_endpoint=AZURE_OPENAI_ENDPOINT, api_key=AZURE_OPENAI_API_KEY, api_version=AZURE_OPENAI_API_VERSION)\n",
    "else:\n",
    "    OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "    oai = OpenAI(api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by getting a text to work with. The Wikipedia article on Elon Musk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Elon_Musk\"  # Replace with the URL of the web page you want to scrape\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "if not os.path.exists('data'): \n",
    "    os.makedirs('data')\n",
    "\n",
    "if not os.path.exists('data/elon.md'):\n",
    "    elon = soup.text.split('\\nSee also')[0]\n",
    "    with open('data/elon.md', 'w', encoding='utf-8') as f:\n",
    "        f.write(elon)\n",
    "else:\n",
    "    with open('data/elon.md', 'r') as f:\n",
    "        elon = f.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GraphRag has a convenient set of CLI commands we can use. We'll start by configuring the system, then run the indexing operation. Indexing with GraphRag is a much lengthier process, and one that costs significantly more, since rather than just calculating embeddings, GraphRag makes many LLM calls to analyse the text, extract entities, and construct the graph. That's a one-time expense, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "if not os.path.exists('data/graphrag'):\n",
    "    !python -m graphrag.index --init --root data/graphrag\n",
    "\n",
    "with open('data/graphrag/settings.yaml', 'r') as f:\n",
    "    settings_yaml = yaml.load(f, Loader=yaml.FullLoader)\n",
    "settings_yaml['llm']['model'] = \"gpt-4o\"\n",
    "settings_yaml['llm']['api_key'] = AZURE_OPENAI_API_KEY if AZURE else OPENAI_API_KEY\n",
    "settings_yaml['llm']['type'] = 'azure_openai_chat' if AZURE else 'openai_chat'\n",
    "settings_yaml['embeddings']['llm']['api_key'] = AZURE_OPENAI_API_KEY if AZURE else OPENAI_API_KEY\n",
    "settings_yaml['embeddings']['llm']['type'] = 'azure_openai_embedding' if AZURE else 'openai_embedding'\n",
    "settings_yaml['embeddings']['llm']['model'] = TEXT_EMBEDDING_3_LARGE_NAME if AZURE else 'text-embedding-3-large'\n",
    "if AZURE:\n",
    "    settings_yaml['llm']['api_version'] = AZURE_OPENAI_API_VERSION\n",
    "    settings_yaml['llm']['deployment_name'] = GPT4O_DEPLOYMENT_NAME\n",
    "    settings_yaml['llm']['api_base'] = AZURE_OPENAI_ENDPOINT\n",
    "    settings_yaml['embeddings']['llm']['api_version'] = AZURE_OPENAI_API_VERSION\n",
    "    settings_yaml['embeddings']['llm']['deployment_name'] = TEXT_EMBEDDING_3_LARGE_NAME\n",
    "    settings_yaml['embeddings']['llm']['api_base'] = AZURE_OPENAI_ENDPOINT\n",
    "\n",
    "with open('data/graphrag/settings.yaml', 'w') as f:\n",
    "    yaml.dump(settings_yaml, f)\n",
    "\n",
    "if not os.path.exists('data/graphrag/input'):\n",
    "    os.makedirs('data/graphrag/input')\n",
    "    !cp data/elon.md data/graphrag/input/elon.txt\n",
    "    !python -m graphrag.index --root ./data/graphrag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get an output:\n",
    "ðŸš€ \u001bAll workflows completed successfully.\u001b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To query GraphRag we'll use its CLI again, making sure to configure it with a context length equivalent to what we use in our embeddings search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import re\n",
    "DEFAULT_RESPONSE_TYPE = 'Summarize and explain in 1-2 paragraphs with bullet points using at most 300 tokens'\n",
    "DEFAULT_MAX_CONTEXT_TOKENS = 10000\n",
    "\n",
    "def remove_data(text):\n",
    "    return re.sub(r'\\[Data:.*?\\]', '', text).strip()\n",
    "\n",
    "\n",
    "def ask_graph(query,method):\n",
    "    env = os.environ.copy() | {\n",
    "      'GRAPHRAG_GLOBAL_SEARCH_MAX_TOKENS': str(DEFAULT_MAX_CONTEXT_TOKENS),\n",
    "    }\n",
    "    command = [\n",
    "      'python', '-m', 'graphrag.query',\n",
    "      '--root', './data/graphrag',\n",
    "      '--method', method,\n",
    "      '--response_type', DEFAULT_RESPONSE_TYPE,\n",
    "      query,\n",
    "    ]\n",
    "    output = subprocess.check_output(command, universal_newlines=True, env=env, stderr=subprocess.DEVNULL)\n",
    "    return remove_data(output.split('Search Response: ')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GrpahRag offers 2 types of search:\n",
    "1. Global Search for reasoning about holistic questions about the corpus by leveraging the community summaries.\n",
    "2. Local Search for reasoning about specific entities by fanning-out to their neighbors and associated concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the local search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Elon Musk has founded several companies and subsidiaries across various industries. Here's a summary:\n",
       "\n",
       "- **SpaceX**: Founded in 2002, SpaceX is a private aerospace manufacturer and space transportation company. Musk serves as the CEO and chief engineer .\n",
       "\n",
       "- **Tesla, Inc.**: Although not originally founded by Musk, he became an early investor and later the CEO and product architect, significantly shaping its direction .\n",
       "\n",
       "- **Neuralink**: Co-founded by Musk, this company focuses on developing brain-machine interfaces to enhance human-computer interaction .\n",
       "\n",
       "- **The Boring Company**: Founded by Musk, it specializes in tunnel construction and innovative transportation solutions .\n",
       "\n",
       "- **X.com/PayPal**: Musk co-founded X.com, which later became PayPal after merging with Confinity .\n",
       "\n",
       "- **Zip2**: Co-founded with his brother Kimbal, this was Musk's first venture, later acquired by Compaq .\n",
       "\n",
       "- **SolarCity**: Co-created by Musk, it was later acquired by Tesla and rebranded as Tesla Energy .\n",
       "\n",
       "- **xAI**: Founded in 2023, this company focuses on artificial intelligence research .\n",
       "\n",
       "- **OpenAI**: Co-founded by Musk, this nonprofit organization is dedicated to AI research .\n",
       "\n",
       "In total, Musk has founded or co-founded at least nine companies and subsidiaries."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "local_query=\"What and how many companies and subsidieries founded by Elon Musk\"\n",
    "local_result = ask_graph(local_query,'local')\n",
    "\n",
    "Markdown(local_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Elon Musk has achieved significant accomplishments across various industries, demonstrating his influence and innovation:\n",
       "\n",
       "- **Space Exploration**: Founder, CEO, and chief engineer of SpaceX, Musk has propelled the company to the forefront of space exploration and satellite deployment, establishing it as a leading spaceflight services provider .\n",
       "\n",
       "- **Automotive Industry**: As CEO of Tesla, Musk has driven the company to the forefront of electric vehicles and sustainable energy, significantly impacting the automotive industry with innovations in electric cars and energy solutions .\n",
       "\n",
       "- **Online Payments**: Co-founded X.com, which evolved into PayPal, revolutionizing online transactions and becoming a major player in the online payment industry .\n",
       "\n",
       "- **Neural Technology**: Co-founded Neuralink, focusing on advancing brain-machine interface technology to enhance the connection between the human brain and computers .\n",
       "\n",
       "- **Infrastructure**: Founded The Boring Company, specializing in tunnel construction to reduce traffic congestion through innovative underground transportation systems ."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_query=\"What are the major accomplishments of Elon Musk?\"\n",
    "global_result = ask_graph(global_query,'global')\n",
    "\n",
    "Markdown(global_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
