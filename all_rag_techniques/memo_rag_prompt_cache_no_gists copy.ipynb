{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# MemoRAG: Enhancing Retrieval-Augmented Generation with Memory Models\n",
    "\n",
    "## Overview\n",
    "MemoRAG is a Retrieval-Augmented Generation (RAG) framework that incorporates a memory model as an auxiliary step before the retrieval phase. In doing so, it bridges the gap in contextual understanding and reasoning that standard RAG techniques face when addressing queries with implicit or ambiguous information needs and unstructured external knowledge.\n",
    "\n",
    "## Motivation\n",
    "Standard RAG techniques rely heavily on lexical or semantic matching between the query and the knowledge base. While this approach works well for clear question answering tasks with structured knowledge, it often falls short when handling queries with implicit or ambiguous information (e.g., describing the relationships between main characters in a novel) or when the knowledge base is unstructured (e.g., fiction books). In such cases, lexical or semantic matching seldom produces the desired outputs.\n",
    "\n",
    "## Key Components\n",
    "1. **Memory**: A compressed representation of the database created by a long-context model, designed to handle and summarize extensive inputs efficiently.\n",
    "2. **Retriever**: A standard RAG retrieval model responsible for selecting relevant context from the knowledge base to support the generator.\n",
    "3. **Generator**: A generative language model that produces responses by combining the query with the retrieved context, similar to standard RAG setups.\n",
    "\n",
    "## Method Details\n",
    "### 1. Memory\n",
    "- The memory module serves as an auxiliary component to enhance the retriever’s ability to identify better matches between queries and relevant parts of the database. It takes the original query and the database as inputs and produces staging answers — intermediate outputs like clues, surrogate queries, or key points — which the retriever uses instead of the original query.\n",
    "- Long-term memory is constructed by running a long-context model, such as Qwen2-7B-Instruct or Mistral-7B-Instruct-v0.2, over the entire database. This process generates a compressed representation of the database through an attention mechanism.\n",
    "- The compressed representation is stored as key-value pairs, facilitating efficient and accurate retrieval.\n",
    "- Released memory models include memorag-qwen2-7b-inst and memorag-mistral-7b-inst, derived from Qwen2-7B-Instruct and Mistral-7B-Instruct-v0.2, respectively.\n",
    "\n",
    "### 2. Retriever\n",
    "- The retriever is a standard retrieval model, adapted to take processed queries (created by the memory module as staging answers) instead of the original query.\n",
    "- It outputs the retrieved **context**, which serves as the basis for generating the final answer.\n",
    "\n",
    "\n",
    "### 3. Generator\n",
    "- The generator produces the final response by combining the retriever’s output (retrieved context) with the original query.\n",
    "- MemoRAG ensures compatibility and consistency by using the memory module’s underlying model as the default generator.\n",
    "\n",
    "## Benefits of the Approach\n",
    "1. **Extended Scope of Queries:** MemoRAG's preprocessing capabilities enable it to handle complex and long-context tasks that conventional RAG methods struggle with.\n",
    "\n",
    "2. **Improved Accuracy:** By simplifying and adjusting queries before retrieval, MemoRAG enhances performance over standard RAG methods.\n",
    "\n",
    "3. **Flexibility:** Adapts to diverse tasks, datasets, and retrieval scenarios.\n",
    "\n",
    "4. **Robustness:** Improved performance remains consistent across various generators, datasets, and query types.\n",
    "\n",
    "5. **Efficiency**: The use of key-value compression reduces computational overhead.\n",
    "\n",
    "## Conclusion\n",
    "The memory module in MemoRAG significantly enhances comprehension of both the queries and the database, enabling more effective retrieval. Its ability to preprocess queries, generate staging answers, and leverage long-context memory models ensures high-quality responses, making MemoRAG a significant step forward in the evolution of retrieval-augmented generation.\n"
   ],
   "id": "67e98dec56de7fdd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/memo_rag.svg\" alt=\"MemoRAG\" style=\"width:100%; height:auto;\">\n",
    "</div>"
   ],
   "id": "abfa998b6aa7d7ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Implementation",
   "id": "76c252dd34083769"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Imports",
   "id": "2bc3b3e34c811bd5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:19:53.264520Z",
     "start_time": "2025-01-26T17:19:52.585030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from weakref import finalize\n",
    "\n",
    "from appdirs import system\n",
    "from dotenv import load_dotenv\n",
    "# from typing import List\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_experimental.graph_transformers.llm import system_prompt\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "# from langchain_community.document_loaders import PyPDFLoader\n",
    "from openai import OpenAI\n",
    "from helper_functions import *\n",
    "from semantic_text_splitter import TextSplitter\n",
    "from itertools import chain\n",
    "\n"
   ],
   "id": "e31a95191a274c83",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### OpenAI Setup",
   "id": "a84d4f5a1fd94512"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:19:53.277245Z",
     "start_time": "2025-01-26T17:19:53.268601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))"
   ],
   "id": "705080e6703ad71c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Memory Module Classes",
   "id": "62fd38f51251d71a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:19:53.383778Z",
     "start_time": "2025-01-26T17:19:53.377298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MemoryStore:\n",
    "    \"\"\"The MemoryStore class is a realization of the Memory Module discussed in the paper.\n",
    "    Its 'memorize' method is used to create a prompt cache mimicking a key-value compression of the original text (database).\n",
    "    This cache can then be used by the 'create_retrieval_prompt' method for creating the processed query to be used later for retrieval\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "        self.store = None\n",
    "        self.processed_count = 0\n",
    "\n",
    "    def memorize(self,\n",
    "                 document: str,\n",
    "                 memory_prompt: str,\n",
    "                 chunk_size: int = 4096):\n",
    "\n",
    "        # self.reset()\n",
    "        # batch_size = 10\n",
    "\n",
    "        system_prompt = \"\"\"\\\n",
    "            You are a highly capable assistant with expertise in reading comprehension\n",
    "            and information extraction. You have been given an article, and you will be asked to perform tasks or answer questions based on that text.\n",
    "\n",
    "            Carefully study the content provided. Use only the information you find within\n",
    "            the text or your general knowledge (when relevant and consistent with the text).\n",
    "            Do not fabricate details. If you do not have enough information to answer a question or complete a task, acknowledge this clearly.\n",
    "\n",
    "            Communicate your answers or completed tasks in a concise, straightforward manner.\n",
    "            \"\"\"\n",
    "\n",
    "        print(f\"Forming prompt cache for the full context\")\n",
    "        _ = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": memory_prompt.format(document=document)}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def create_retrieval_query(self, query: str, context: str) -> str:\n",
    "        \"\"\"Generate staging answers y = Θ_mem(q, D | θ_mem)\n",
    "        This should provide rough clues/outline to guide context retrieval\"\"\"\n",
    "\n",
    "        memorag_span_prompt = \"\"\"\n",
    "            You are given a question related to the article. To answer it effectively, you need to recall specific details from the article. Your task is to identify and extract one or more specific clue texts from the article that are relevant to the question.\n",
    "\n",
    "            ### Question: {question}\n",
    "            ### Instructions:\n",
    "            1. You have a general understanding of the article. Your task is to generate one or more specific clues that will help in searching for supporting evidence within the article.\n",
    "            2. The clues are in the form of text spans that will assist in answering the question.\n",
    "            3. Only output the clues. If there are multiple clues, separate them with a newline.\n",
    "            \"\"\"\n",
    "        memorag_sur_prompt = \"\"\"\n",
    "            You are given a question related to the article. To answer it effectively, you need to recall specific details from the article. Your task is to generate precise clue questions that can help locate the necessary information.\n",
    "\n",
    "            ### Question: {question}\n",
    "            ### Instructions:\n",
    "            1. You have a general understanding of the article. Your task is to generate one or more specific clues that will help in searching for supporting evidence within the article.\n",
    "            2. The clues are in the form of precise surrogate questions that clarify the original question.\n",
    "            3. Only output the clues. If there are multiple clues, separate them with a newline.\n",
    "            \"\"\"\n",
    "        system_prompt = \"\" ## need to define this\n",
    "\n",
    "        text_spans = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": memory_prompt.format(document=context) + memorag_span_prompt.format(question=query)}\n",
    "            ]\n",
    "        )\n",
    "        surrogate_queries = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": memory_prompt.format(document=context) + memorag_sur_prompt.format(question=query)}\n",
    "            ],\n",
    "            temperature=0.5  # Allow for some creativity in generating clues\n",
    "        )\n",
    "\n",
    "        retrieval_query = text_spans.split(\"\\n\") + surrogate_queries.split(\"\\n\")\n",
    "        retrieval_query = [q for q in retrieval_query if len(q.split()) > 3]\n",
    "        retrieval_query.append(query)\n",
    "\n",
    "        return retrieval_query\n",
    "\n",
    "\n",
    "    # def __call__(\n",
    "    #     self,\n",
    "    #     query: str = None,\n",
    "    #     context: str = None,\n",
    "    #     task_type: str = \"memorag\",\n",
    "    #     memory_prompt: str = None,\n",
    "    #     prompt_template: str = None,\n",
    "    #     max_new_tokens: int = 256\n",
    "    # ):\n",
    "    #\n",
    "    #     ## OR\n",
    "    #\n",
    "    #     topk_scores, topk_indices = retriever.search(queries=retrieval_query)\n",
    "    #     topk_indices = list(chain(*[topk_index.tolist() for topk_index in topk_indices]))\n",
    "    #     topk_indices = sorted(set([x for x in topk_indices if x > -1]))\n",
    "    #     retrieval_results = [retrieval_corpus[i].strip() for i in topk_indices]\n",
    "    #     knowledge = \"\\n\\n\".join(retrieval_results)\n",
    "    #     # final_answer = _generate_response(\"qa_gen\", query, knowledge, prompt_template, max_new_tokens)\n",
    "\n",
    "    def save_store(self, path: str):\n",
    "        if self.store:\n",
    "            self.store.save_local(path)\n",
    "\n",
    "    def load_store(self, path: str):\n",
    "        self.store = FAISS.load_local(path, self.embeddings, allow_dangerous_deserialization=True)"
   ],
   "id": "5f823410ae7deb9b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Retrieval Function",
   "id": "5129a38d93eef1ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:19:53.395533Z",
     "start_time": "2025-01-26T17:19:53.393206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve_context(retrieval_query: str, vectorstore) -> List[str]:\n",
    "    \"\"\"Retrieve relevant context using the staging answer and the database vectorstore.\n",
    "    Implements c = Γ(y, D | γ) from the paper\"\"\"\n",
    "\n",
    "    results = vectorstore.similarity_search(retrieval_query, k=5)\n",
    "    contexts = [doc.page_content for doc in results]\n",
    "\n",
    "    return contexts"
   ],
   "id": "bc049fa0d88b8546",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Generation Function",
   "id": "f38ef305cf0cc904"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:19:55.665705Z",
     "start_time": "2025-01-26T17:19:55.662479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_answer(query: str, contexts: List[str]) -> str:\n",
    "    \"\"\"Generate final answer y = Θ(q, c | θ)\"\"\"\n",
    "    prompt = f\"\"\"Based on the provided context, answer the query.\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Retrieved Information:\n",
    "{' '.join(contexts)}\n",
    "\n",
    "Provide a clear and concise answer focusing only on the retrieved information.\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant. Provide clear, concise answers.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ],
   "id": "ab53db37ee3502ad",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Query Processing Function",
   "id": "66ca6ece210c2c18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:19:58.214130Z",
     "start_time": "2025-01-26T17:19:58.210576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_query(query: str, memory_store, vectorstore):\n",
    "    print(\"\\nProcessing Query:\", query)\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # y = Θ_mem(q, D | θ_mem)\n",
    "    retrieval_query = memory_store.create_retrieval_query(query)\n",
    "    print(f\"Staging Answer:\\n{retrieval_query}\")\n",
    "\n",
    "    # c = Γ(y, D | γ)\n",
    "    contexts = retrieve_context(retrieval_query, vectorstore)\n",
    "    print(f\"Retrieved Context Example: {contexts[0]}\")\n",
    "\n",
    "    # y = Θ(q, c | θ)\n",
    "    final_answer = generate_answer(query, contexts)\n",
    "    print(f\"\\nFinal Answer: {final_answer}\")\n",
    "\n",
    "    return contexts, final_answer"
   ],
   "id": "e3e4c2970f0f8641",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "memory_prompt = \"\"\"You are provided with a long article. Read the article carefully. After reading, you will be asked to perform specific tasks based on the content of the article.\n",
    "\n",
    "                    Now, the article begins:\n",
    "                    - **Article Content:** {document}\n",
    "\n",
    "                    The article ends here.\n",
    "\n",
    "                    Next, follow the instructions provided to complete the tasks.\n",
    "                \"\"\""
   ],
   "id": "25573e123f288c30"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Initialize Components",
   "id": "4f5e51437c7d37c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:20:14.557084Z",
     "start_time": "2025-01-26T17:20:05.002353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize memory store\n",
    "memory_store = MemoryStore()\n",
    "\n",
    "# Load and process document\n",
    "path = \"../data/Understanding_Climate_Change.pdf\"\n",
    "loader = PyPDFLoader(path)\n",
    "documents = loader.load()\n",
    "document_text = '\\n'.join([doc.page_content for doc in documents])\n",
    "memory_store.memorize(memory_prompt, document_text)\n",
    "## pipe = mem_store.call(query ...)\n",
    "chunks_vector_store = encode_pdf(path, chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "# retrieval_chunk_size = 2048\n",
    "#         text_splitter_for_retrieval = TextSplitter.from_tiktoken_model(\n",
    "#             \"gpt-4o-mini\", retrieval_chunk_size)\n",
    "#         retrieval_corpus = text_splitter_for_retrieval.chunks(document)"
   ],
   "id": "698e3786c420c76f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1...\n",
      "Processed 1 chunks so far\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Usage Examples",
   "id": "63e823251233ca38"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T17:20:27.511606Z",
     "start_time": "2025-01-26T17:20:14.565406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_1 = \"What are the impacts of climate change on biodiversity?\"\n",
    "query_2 = \"Please summarize the climate change article\"\n",
    "query_3 = \"Describe the social and economic influence of climate change.\"\n",
    "\n",
    "for query in [query_1, query_2, query_3]:\n",
    "    process_query(query, memory_store, chunks_vector_store)"
   ],
   "id": "e458df9a279c725e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Query: What are the impacts of climate change on biodiversity?\n",
      "==================================================\n",
      "Staging Answer:\n",
      "I. Introduction\n",
      "    A. Definition of climate change\n",
      "    B. Overview of its causes and impacts\n",
      "\n",
      "II. Effects of Climate Change\n",
      "    A. Rising temperatures\n",
      "    B. Heatwaves\n",
      "    C. Changing seasons\n",
      "    D. Melting ice and rising sea levels\n",
      "    E. Glacial retreat\n",
      "    F. Coastal erosion\n",
      "    G. Extreme weather events\n",
      "\n",
      "III. Impact on Biodiversity\n",
      "    A. Deforestation in tropical rainforests\n",
      "    B. Global carbon cycles\n",
      "    C. Impacts on biodiversity\n",
      "\n",
      "IV. Modern Scientific Observations\n",
      "    A. Rapid increases in global temperatures\n",
      "    B. Rising sea levels\n",
      "    C. Extreme weather events\n",
      "    D. Human-induced contributions to climate change\n",
      "\n",
      "V. Agriculture's Contribution to Climate Change\n",
      "    A. Livestock emissions\n",
      "    B. Rice cultivation\n",
      "    C. Use of synthetic fertilizers\n",
      "    D. Release of greenhouse gases\n",
      "\n",
      "VI. Conclusion\n",
      "    A. Summary of key points regarding the impacts of climate change on biodiversity\n",
      "Retrieved Context Example: Understanding Climate Change  \n",
      "Chapter 1: Introduction to Climate Change  \n",
      "Climate change refers to significant, long -term changes in the global climate. The term \n",
      "\"global climate\" encompasses the planet's overall weather patterns, including temperature, \n",
      "precipitation, and wind patterns, over an extended period. Over the past cent ury, human \n",
      "activities, particularly the burning of fossil fuels and deforestation, have significantly \n",
      "contributed to climate change.  \n",
      "Historical Context  \n",
      "The Earth's climate has changed throughout history. Over the past 650,000 years, there have \n",
      "been seven cycles of glacial advance and retreat, with the abrupt end of the last ice age about \n",
      "11,700 years ago marking the beginning of the modern climate era and  human civilization. \n",
      "Most of these climate changes are attributed to very small variations in Earth's orbit that \n",
      "change the amount of solar energy our planet receives. During the Holocene epoch, which\n",
      "Final Answer: Climate change impacts biodiversity by altering terrestrial and marine ecosystems through habitat shifts, changing species distributions, and disrupting ecological balance. This can lead to a loss of biodiversity and affect various plant and animal species, ultimately impacting ecosystem functions.\n",
      "\n",
      "Processing Query: Please summarize the climate change article\n",
      "==================================================\n",
      "Staging Answer:\n",
      "I. Introduction to Climate Change\n",
      "    A. Definition and causes of climate change\n",
      "II. Effects of Climate Change\n",
      "    A. Rising temperatures and heatwaves\n",
      "    B. Changing seasons and melting ice\n",
      "    C. Rising sea levels and glacial retreat\n",
      "    D. Coastal erosion and extreme weather events\n",
      "III. Historical Climate Changes\n",
      "    A. Overview of Earth's climate history\n",
      "    B. Glacial advance and retreat cycles\n",
      "IV. Modern Scientific Observations\n",
      "    A. Rapid increases in global temperatures and sea levels\n",
      "    B. Impact of extreme weather events\n",
      "V. Agriculture's Contribution to Climate Change\n",
      "    A. Livestock emissions and rice cultivation\n",
      "    B. Use of synthetic fertilizers and greenhouse gas emissions\n",
      "Retrieved Context Example: Understanding Climate Change  \n",
      "Chapter 1: Introduction to Climate Change  \n",
      "Climate change refers to significant, long -term changes in the global climate. The term \n",
      "\"global climate\" encompasses the planet's overall weather patterns, including temperature, \n",
      "precipitation, and wind patterns, over an extended period. Over the past cent ury, human \n",
      "activities, particularly the burning of fossil fuels and deforestation, have significantly \n",
      "contributed to climate change.  \n",
      "Historical Context  \n",
      "The Earth's climate has changed throughout history. Over the past 650,000 years, there have \n",
      "been seven cycles of glacial advance and retreat, with the abrupt end of the last ice age about \n",
      "11,700 years ago marking the beginning of the modern climate era and  human civilization. \n",
      "Most of these climate changes are attributed to very small variations in Earth's orbit that \n",
      "change the amount of solar energy our planet receives. During the Holocene epoch, which\n",
      "Final Answer: The article discusses the significant long-term changes in global climate known as climate change. It highlights the historical context of climate change, emphasizing human activities like burning fossil fuels as significant contributors. Modern observations show rapid increases in global temperatures, sea levels, and extreme weather events, primarily driven by human activities and greenhouse gas emissions. The article also outlines the causes and effects of climate change, including rising temperatures, heatwaves, changing seasons, melting ice, rising sea levels, extreme weather events like hurricanes and typhoons, droughts, and flooding.\n",
      "\n",
      "Processing Query: Describe the social and economic influence of climate change.\n",
      "==================================================\n",
      "Staging Answer:\n",
      "I. Introduction to Climate Change\n",
      "    A. Definition and causes\n",
      "    B. Impact on global climate\n",
      "\n",
      "II. Effects of Climate Change\n",
      "    A. Rising temperatures and heatwaves\n",
      "    B. Changing seasons and melting ice\n",
      "    C. Rising sea levels and coastal erosion\n",
      "    D. Extreme weather events\n",
      "\n",
      "III. Social Influence of Climate Change\n",
      "    A. Impact on communities\n",
      "    B. Economic repercussions\n",
      "    C. Displacement of populations\n",
      "\n",
      "IV. Economic Influence of Climate Change\n",
      "    A. Impact on industries and economies\n",
      "    B. Costs of adaptation and mitigation measures\n",
      "    C. Long-term economic implications\n",
      "\n",
      "V. Human Contribution to Climate Change\n",
      "    A. Role of human activities like burning fossil fuels\n",
      "    B. Agriculture's contribution to greenhouse gas emissions\n",
      "    C. Historical context of climate changes\n",
      "\n",
      "VI. Conclusion: Overall impact and the need for global action\n",
      "Retrieved Context Example: Understanding Climate Change  \n",
      "Chapter 1: Introduction to Climate Change  \n",
      "Climate change refers to significant, long -term changes in the global climate. The term \n",
      "\"global climate\" encompasses the planet's overall weather patterns, including temperature, \n",
      "precipitation, and wind patterns, over an extended period. Over the past cent ury, human \n",
      "activities, particularly the burning of fossil fuels and deforestation, have significantly \n",
      "contributed to climate change.  \n",
      "Historical Context  \n",
      "The Earth's climate has changed throughout history. Over the past 650,000 years, there have \n",
      "been seven cycles of glacial advance and retreat, with the abrupt end of the last ice age about \n",
      "11,700 years ago marking the beginning of the modern climate era and  human civilization. \n",
      "Most of these climate changes are attributed to very small variations in Earth's orbit that \n",
      "change the amount of solar energy our planet receives. During the Holocene epoch, which\n",
      "Final Answer: The social and economic influence of climate change includes disruptions to ecosystems and human activities due to changing seasons, melting ice leading to rising sea levels threatening coastal communities, and more frequent and severe extreme weather events like heatwaves, hurricanes, droughts, and flooding. These impacts can result in adverse effects on human health, agriculture, infrastructure, and economies, necessitating investments in resilience and adaptation measures to mitigate risks and address the challenges posed by climate change.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Comparison",
   "id": "13af1e5e102361c7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
